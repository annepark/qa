{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task fMRI QA Notebook\n",
    "---\n",
    "Notebook for visualizing quality assurance outputs of the [openfMRI subject-level task fMRI script](https://github.com/gablab/openfmri/blob/openfmri/subject_level/fmri_ants_openfmri.py):\n",
    "- coregistration (functional to structural: bbregister)\n",
    "- normalization (structural to MNI template: ANTS)\n",
    "- ART outliers\n",
    "- analysis masks (used during model fitting: FLAMEO)\n",
    "- Z-stat maps\n",
    "- temporal signal-to-noise ratio\n",
    "- stimulus-correlated motion\n",
    "\n",
    "The cells will display either brain slices or plots that allow for quick detection of potential problems. You must run the first 3 cells in order to use the rest of the notebook. The notebook also assumes that you used a script like dicomconvert2.py or heudiconv to convert your dicoms (the output directories of these scripts are typically named 'BOLD', 'anatomy', etc.)\n",
    "\n",
    "See below for required packages.\n",
    "\n",
    "(*updated Sep 3, 2016*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import fnmatch\n",
    "import nilearn.plotting as nlp\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project-specific variables to change ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "openfmri_dir = '/mindhive/xnat/data/READ/openfmri/'\n",
    "l1_dir = '/gablab/p/READ/openfmri_task/l1output/'\n",
    "subj_prefix = 'READ_*'\n",
    "fs_dir = '/mindhive/xnat/surfaces/lex/READ'   # set to None if no freesurfer dir\n",
    "model_subset = ['model01']   # set to None to see all models --> if you set to None, the\n",
    "                              # notebook will only look for model directories with 2 digits. \n",
    "                              # If your l1 model directories have 3 digits, list them here\n",
    "skip_tasks = ['task002']   # set to empty list to see all tasks\n",
    "subj_subset = ['READ_2000', 'READ_2009', 'READ_2010', 'READ_2047', 'READ_2089']\n",
    "              # set to None to see all subjects\n",
    "outlier_threshold = 20    # percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up models, tasks, subject lists, runs, # of vols, contrasts, etc. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if model_subset == None:\n",
    "    models = [task.split('/')[-1] for task in sorted(glob.glob(os.path.join(l1_dir, 'model??')))]\n",
    "    # grabs models in the l1_dir with just 2 digits\n",
    "  \n",
    "else:\n",
    "    models = model_subset\n",
    "\n",
    "def get_tasks(model):\n",
    "    tasks = [task.split('/')[-1] for task in sorted(glob.glob(os.path.join(l1_dir, model, 'task*')))]\n",
    "    return [task for task in tasks if task not in skip_tasks]\n",
    "\n",
    "def get_subjlist(model, task):\n",
    "    if subj_subset == None:\n",
    "        subjlist = [fl for fl in sorted(os.listdir(os.path.join(l1_dir, model, task))) \n",
    "                    if fnmatch.fnmatch(fl, subj_prefix)]\n",
    "    else:    \n",
    "        subjlist = subj_subset\n",
    "    return sorted(subjlist)\n",
    "\n",
    "def get_subjtask(model):\n",
    "    df = pd.DataFrame()\n",
    "    for task in get_tasks(model):\n",
    "        subjects = get_subjlist(model, task)\n",
    "        df[task] = pd.Series([1 for subj in subjects], index=subjects)\n",
    "    return df\n",
    "\n",
    "def get_runs(task, subj):\n",
    "    task_runs = sorted(os.listdir(os.path.join(openfmri_dir, subj, 'BOLD')))\n",
    "    num_runs = 0\n",
    "    for run in task_runs:\n",
    "        if run.split('_')[0] == task:\n",
    "            num_runs += 1\n",
    "    return num_runs\n",
    "\n",
    "def get_num_vols(task, subj, run):\n",
    "    bold_file = os.path.join(openfmri_dir,subj,'BOLD','%s_run%03d' % (task,run+1),'bold.nii.gz')\n",
    "    bold_img = nb.load(bold_file)\n",
    "    return bold_img.shape[3]\n",
    "\n",
    "def get_contrasts(model, task):\n",
    "    contrasts_dict = {}\n",
    "    model_num = int(model.split('model')[1])   # quick fix for discrepancy between 'model01' and 'model001'\n",
    "    model = 'model%03d' % model_num\n",
    "    task_contrasts = os.path.join(openfmri_dir, 'models', model, 'task_contrasts.txt')\n",
    "    with open(task_contrasts, 'r') as f:\n",
    "        contrasts = [line.split()[1] for line in f if line.split()[0]==task]\n",
    "    condition_key = os.path.join(openfmri_dir, 'models', model, 'condition_key.txt')\n",
    "    with open(condition_key, 'r') as f:\n",
    "        conditions = [line.split()[2].strip() for line in f if line.split()[0]==task]\n",
    "    with open(condition_key, 'r') as f:\n",
    "        cond_gt_rest = [line.split()[2].strip() + '_gt_rest' for line in f \\\n",
    "                        if line.split()[0]==task]\n",
    "    contrasts.extend(cond_gt_rest)\n",
    "    return conditions, contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_mean2anat_overlay(subj, subj_path, fs_dir, title, fig=None, ax=None):   \n",
    "    if fs_dir == None:\n",
    "        bg = os.path.join(openfmri_dir, subj, 'anatomy', 'T1_001.nii.gz')\n",
    "    else:\n",
    "        bg = os.path.join(fs_dir, subj, 'mri', 'T1.mgz')\n",
    "    mask = os.path.join(os.path.join(subj_path,'qa','mask','mean2anat',\n",
    "                                     'median_brain_mask.nii.gz'))\n",
    "    close = False\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(5, 2))\n",
    "        ax = fig.gca()\n",
    "        close = True\n",
    "    display = nlp.plot_roi(roi_img=mask, bg_img=bg, black_bg=False, alpha=0.3, \n",
    "                           draw_cross=False, annotate=False,\n",
    "                           figure=fig, axes=ax, title=title)\n",
    "    if close:\n",
    "        plt.show()\n",
    "        display.close()\n",
    "\n",
    "def plot_anat(subj_path, title, fig=None, ax=None):\n",
    "    anat2target = os.path.join(subj_path, 'qa', 'anat2target', 'output_warped_image.nii.gz')\n",
    "    close = False\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(5, 2))\n",
    "        ax = fig.gca()\n",
    "        close = True\n",
    "    display = nlp.plot_anat(anat_img=anat2target, cut_coords=(0, -13, 20), annotate=False,\n",
    "                            draw_cross=False, title=title, figure=fig, axes=ax)\n",
    "    if close:\n",
    "        plt.show()\n",
    "        display.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check registration of mean (median) functional to structural ###\n",
    "\n",
    "Displays a mask (blue) of the coregistered median functional image overlaid on the subject's T1. Check for cases where the mask is not lined up with the brain. **Note:** this tool can only be used if you ran the version of the subject-level script that outputs a qa/mask/mean2anat directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print '********** %s **********' % model\n",
    "    subj_df = get_subjtask(model)\n",
    "    for subj in subj_df.index:\n",
    "        fig, ax = plt.subplots(1, subj_df.shape[1], figsize=(4 * subj_df.shape[1], 2))\n",
    "        if not isinstance(ax, np.ndarray):\n",
    "            ax = [ax]\n",
    "        for idx, task in enumerate(subj_df.ix[subj].index):\n",
    "            if subj_df.ix[subj, task]:\n",
    "                plot_mean2anat_overlay(subj, os.path.join(l1_dir, model, task, subj), \n",
    "                                       fs_dir, title=subj + '-' + task, fig=fig, ax=ax[idx])\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check registration of structural to MNI template ###\n",
    "\n",
    "Displays cross-sections of the output of ANTS registration (the structural image warped to the MNI template). Do the brains look like MNI brains?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print '********** %s **********' % model\n",
    "    subj_df = get_subjtask(model)\n",
    "    for subj in subj_df.index:\n",
    "        fig, ax = plt.subplots(1, subj_df.shape[1], figsize=(4 * subj_df.shape[1], 2))\n",
    "        if not isinstance(ax, np.ndarray):\n",
    "            ax = [ax]\n",
    "        for idx, task in enumerate(subj_df.ix[subj].index):\n",
    "            if subj_df.ix[subj, task]:\n",
    "                plot_anat(os.path.join(l1_dir, model, task, subj), title=subj + '-' + task, fig=fig, ax=ax[idx])\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_outliers(subj_path, run):\n",
    "    outlier_file = os.path.join(subj_path, 'qa', 'art', \n",
    "                                'run%02d_art.bold_dtype_mcf_outliers.txt' % (run + 1))\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        outliers = np.genfromtxt(outlier_file)\n",
    "    return np.prod(outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check percentage of outliers per run ###\n",
    "\n",
    "Displays a heatmap of the percentage of outliers detected in each run. Darker = more outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outlier_dfs = {}\n",
    "for model in models:\n",
    "    df = pd.DataFrame()\n",
    "    print '********** %s **********' % model\n",
    "    tasks = get_tasks(model)\n",
    "    for task in tasks:\n",
    "        subjects = get_subjlist(model, task)\n",
    "        max_run = 0\n",
    "        subj_runs = {}\n",
    "        for subj in subjects:\n",
    "            num_runs = get_runs(task, subj)\n",
    "            subj_runs[subj] = num_runs\n",
    "            if num_runs > max_run:\n",
    "                max_run = num_runs\n",
    "        task_info = np.zeros((len(subjects), max_run))\n",
    "        columns = ['%s-Run%02d' % (task, run) for run in range(1, max_run + 1)]\n",
    "        for idx, subj in enumerate(subjects):\n",
    "            for run in range(subj_runs[subj]):\n",
    "                num_outliers = count_outliers(os.path.join(l1_dir, model, task, subj), run) \n",
    "                num_vols = get_num_vols(task,subj,run)\n",
    "                task_info[idx, run] = float(num_outliers)/num_vols\n",
    "        df_task = pd.DataFrame(task_info, index=subjects, columns=columns)\n",
    "        df = pd.concat((df, df_task), axis=1)\n",
    "    sns.set(context=\"poster\", font=\"monospace\")\n",
    "    f, ax = plt.subplots(figsize=(20, 0.75*len(df.index)))\n",
    "    sns.heatmap(df, linewidths=0, annot=True, vmax=outlier_threshold/100., vmin=0), #vmax=1, vmin=-1, \n",
    "    f.tight_layout()\n",
    "    outlier_dfs[model] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you ran the previous cell and would like the outlier percentages outputted in csv form: ###\n",
    "\n",
    "Indicate an output directory for the csv file below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_outdir = '/path/to/csv/outdir/'  # USER OPTION\n",
    "\n",
    "df.to_csv(os.path.join(csv_outdir, 'outlier_summary.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or, if you would like to see Python lists of the subjects that exceed your specified threshold: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outlier_names = {}\n",
    "for model in models:\n",
    "    tasks = get_tasks(model)\n",
    "    cols = outlier_dfs[model].columns.values.tolist()\n",
    "    for task in tasks:\n",
    "        task_cols = [col for col in cols if task in col]\n",
    "        outlier_df = outlier_dfs[model][task_cols]\n",
    "        outlier_names[model+'-'+task] = outlier_df.index[np.nonzero((outlier_df > outlier_threshold/100.).sum(axis=1))[0]].tolist()\n",
    "\n",
    "outlier_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masks #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_mask(subj_path,run):\n",
    "    mask = os.path.join(subj_path,'qa','mask','run%02d_mask.nii.gz' % (run+1))\n",
    "    bg = os.path.join(subj_path, 'mean', 'median.nii.gz')\n",
    "\n",
    "    display = nlp.plot_roi(roi_img=mask, bg_img=bg, black_bg=False, alpha=0.3, display_mode='y', cut_coords=15)\n",
    "    plt.show()\n",
    "    display.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check analysis masks (used at FLAMEO step) for areas of poor coverage ###\n",
    "\n",
    "Displays coronal slices of the mask (blue) overlaid on the median functional image, per run. Check for masks with poor coverage (any holes? missing sections?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print '********** %s **********' % model\n",
    "    tasks = get_tasks(model)\n",
    "    for task in tasks:\n",
    "        print '********** %s **********' % task\n",
    "        for subj in get_subjlist(model, task):\n",
    "            print subj\n",
    "            num_runs = get_runs(task, subj)\n",
    "            for run in range(num_runs):\n",
    "                print 'run%02d' % (run + 1)\n",
    "                plot_mask(os.path.join(l1_dir,model,task,subj),run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-Stat Maps #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_stat_map(subj_path, contrast_num, display_mode, threshold, title):\n",
    "    zstat = os.path.join(subj_path,'zstats','mni','zstat%02d.nii.gz' % (contrast_num + 1))\n",
    "    fig = plt.figure(figsize=(15, 2))\n",
    "    if display_mode == 'x':\n",
    "        cut_coords=np.linspace(-50, 60, 12)\n",
    "    elif display_mode == 'y':\n",
    "        cut_coords=np.linspace(-90, 50, 12)\n",
    "    elif display_mode == 'z':\n",
    "        cut_coords=np.linspace(-40, 70, 12)\n",
    "    display = nlp.plot_stat_map(stat_map_img=zstat, display_mode=display_mode, threshold=threshold, \n",
    "                                figure=fig, black_bg=True, cut_coords=cut_coords, \n",
    "                                title=title, annotate=False)\n",
    "    plt.show()\n",
    "    display.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look through Z-stat maps in MNI space ###\n",
    "\n",
    "Displays slices of each contrast's Z-stat map. You can change the Z threshold or the display mode below (default: Z=2.3, display_mode='z'):\n",
    "\n",
    "'x' = sagittal;\n",
    "'y' = coronal;\n",
    "'z' = axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_mode = 'z'   # USER OPTION\n",
    "threshold = 2.3      # USER OPTION\n",
    "\n",
    "for model in models:\n",
    "    print '********** %s **********' % model \n",
    "    for task in get_tasks(model):\n",
    "        print '********** %s **********' % task\n",
    "        conditions, contrasts = get_contrasts(model,task)\n",
    "        for contrast_num in range(len(contrasts)):\n",
    "            print contrasts[contrast_num]\n",
    "            for subj in get_subjlist(model, task):\n",
    "                plot_stat_map(os.path.join(l1_dir, model, task, subj), contrast_num, \n",
    "                              display_mode, threshold, title=subj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Signal-to-Noise Ratio (tSNR) #\n",
    "\n",
    "Note: this tool can only be used if you ran the subject-level script using the FreeSurfer registration workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_stats(fname):\n",
    "    statsname = fname.split('_aparc')[0] + '_summary.stats'\n",
    "    roi = np.genfromtxt(statsname, dtype=object)[:, 4]\n",
    "    data = np.genfromtxt(fname)\n",
    "    return dict(zip(roi, data))\n",
    "\n",
    "import re\n",
    "\n",
    "def get_data(fl, subj_regex):\n",
    "    data = None\n",
    "    for i, name in enumerate(fl):\n",
    "        subjid = re.search(subj_regex, name).group()\n",
    "        df = pd.DataFrame(read_stats(name), index=[subjid])\n",
    "        if data is None:\n",
    "            data = df\n",
    "        else:\n",
    "            data = pd.concat((data, df))\n",
    "    return data.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for subjects with a tSNR profile that differs from that of other subjects ###\n",
    "\n",
    "Displays a heatmap of the \"% tSNR dissimilarity\" for each subject. The subject-level script outputs a tSNR summary file with information on the mean tSNR within each of the FreeSurfer ROIs. This tool looks at the correlations between the subjects' overall tSNR profiles. Here, \"% tSNR dissimilarity\" refers to the percentage of subjects for which a subject had a correlation of r < 0.8 (correlations were performed within tasks/runs, and for all subjects in your l1_dir). Darker = tSNR profile is less similar. \n",
    "\n",
    "**You need to set the subj_regex variable to use the following cell.** subj_regex is your subject ID prefix, followed by one dot for each of the remaining characters. **Note**: this only works if all your subject IDs are the same length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subj_regex = 'READ_....'  # USER OPTION (e.g. subject IDs are READ_1002, READ_1004, etc.)\n",
    "\n",
    "for model in models:\n",
    "    print '********** %s **********' % model \n",
    "    df = pd.DataFrame()\n",
    "    for task in get_tasks(model):\n",
    "        subjects = get_subjlist(model, task)\n",
    "        max_run = 0\n",
    "        subj_runs = {}\n",
    "        for subj in subjects:\n",
    "            num_runs = get_runs(task, subj)\n",
    "            subj_runs[subj] = num_runs\n",
    "            if num_runs > max_run:\n",
    "                max_run = num_runs\n",
    "        for run in range(max_run):\n",
    "            fl = sorted(glob.glob(os.path.join(l1_dir, model, task, subj_prefix,\n",
    "                                                'qa','tsnr','run%02d_aparc+aseg_warped_avgwf.txt' % (run+1))))\n",
    "            data = get_data(fl, subj_regex)\n",
    "            idx = np.nonzero(data.median(axis=0) > 20)[0]\n",
    "            data_trimmed = data.ix[:, idx]\n",
    "            df_task = pd.Series((np.corrcoef(data_trimmed) < 0.8).sum(axis=0), index=data.index, \n",
    "                                name=task+'-run%03d' % (run+1))\n",
    "            df = pd.concat((df, df_task), axis=1)\n",
    "    df = df/df.shape[0]\n",
    "    col_names = df.columns.values.tolist()\n",
    "    sns.set(context=\"poster\", font=\"monospace\")\n",
    "    f, ax = plt.subplots(figsize=(20, 0.25*len(df.index)))\n",
    "    sns.heatmap(df, linewidths=0, annot=True)#, #vmax=1, vmin=-1, \n",
    "    ax.tick_params(labelbottom='on',labeltop='on')\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displays histograms of the \"% tSNR dissimilarity\" measure for each task and run: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(len(col_names), sharex=True, sharey=True, \n",
    "                        figsize=(7,3*len(col_names)), squeeze=False)\n",
    "plt.xlabel('% tSNR dissimilarity', fontsize=20)\n",
    "\n",
    "for i, col_name in enumerate(col_names):\n",
    "    axarr[i,0].hist(df.values[:,i][~np.isnan(df.values[:,i].flatten())], 30)\n",
    "    axarr[i,0].set_title(col_names[i], fontsize=16)\n",
    "    axarr[i,0].set_ylabel('# of participants', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows a Python list of the subjects that have at least 40% tSNR dissimilarity in at least one task/run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsnr_outliers = df.index[np.nonzero((df >= .4).sum(axis=1))[0]].tolist()\n",
    "tsnr_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stimulus-Correlated Motion #\n",
    "\n",
    "### Check for subjects with high levels of stimulus-correlated motion (e.g. greater than r=0.2-0.3) ###\n",
    "\n",
    "It's easier to run this SCM tool one task at a time; you can change the model or task below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = 'model01'   # USER OPTION\n",
    "task = 'task001'     # USER OPTION\n",
    "\n",
    "conditions, contrasts = get_contrasts(model, task)\n",
    "n_conds = len(conditions)\n",
    "\n",
    "cols = []\n",
    "for cond_idx in range(n_conds):\n",
    "    motion_cols = ['cond%s_mot%s' % (cond_idx+1, mot_idx+1) for mot_idx in range(6)]\n",
    "    motion_cols.append('cond%d_outliers' % (cond_idx+1))\n",
    "    cols = cols + motion_cols\n",
    "    \n",
    "output = pd.DataFrame()\n",
    "\n",
    "subs_idx = []\n",
    "runs_idx = []\n",
    "\n",
    "subjects = get_subjlist(model, task)\n",
    "for subj in subjects:\n",
    "    corr_df = pd.DataFrame()\n",
    "    num_runs = get_runs(task, subj)\n",
    "    for run in range(num_runs):\n",
    "        subs_idx.append(subj)\n",
    "        runs_idx.append(run+1)\n",
    "        multiindex = []\n",
    "        multiindex = [np.array(subs_idx), np.array(runs_idx)]\n",
    "        mat = pd.read_csv(os.path.join(l1_dir, model, task, subj, 'qa', 'model', 'run0%s_run%s.mat' \n",
    "                                        % (run+1, run)), delimiter='\\t', skiprows=5, header=None)\n",
    "        mat = mat.dropna(axis=1)\n",
    "        # merging outliers into one vector\n",
    "        outliers = np.genfromtxt(os.path.join(l1_dir, model, task, subj, 'qa', 'art', \n",
    "                                    'run0%s_art.bold_dtype_mcf_outliers.txt' %(run+1)), dtype='int')\n",
    "        outlier_regressors = mat.ix[:,n_conds+6:len(mat.columns)]\n",
    "        outliers_all = pd.DataFrame(outlier_regressors.sum(axis=1))\n",
    "        # getting slice of just the conditions and motion regressors\n",
    "        cond_slice = mat.ix[:,0:n_conds-1]\n",
    "        mot_slice = mat.ix[:,n_conds:n_conds+5]\n",
    "        mot_slice = pd.concat([mot_slice, outliers_all], axis=1, ignore_index=True)\n",
    "        mat_slice = pd.concat([cond_slice, mot_slice], axis=1, ignore_index=True)\n",
    "        # calculating correlation between the conditions and motion regressors\n",
    "        corr_list = [pearsonr(mat_slice.ix[:,i], mat_slice.ix[:,j])[0] for i in range(n_conds) \n",
    "                        for j in range(n_conds, mat_slice.shape[1])]  \n",
    "        row = pd.DataFrame([corr_list], columns=cols)\n",
    "        corr_df = pd.concat([corr_df, row], ignore_index=True)\n",
    "    output = pd.concat([output, corr_df], axis=0, ignore_index=True)\n",
    "    \n",
    "output = pd.DataFrame(output.values, index=multiindex, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the plot here: ###\n",
    "\n",
    "Displays a plot of the correlations (absolute value) between each condition and the 6 motion parameters used in the model. Also shows the correlations between each condition and the outlier volumes (represented here as a single time series collapsed across all outlier columns in the model).\n",
    "\n",
    "You can take a look at the model .mat files in your qa/model l1 directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'axes.labelsize': 25}, font_scale=1.2)\n",
    "f, ax = plt.subplots(figsize=(25,len(subjects)*1.5))  # change second argument to make plot larger\n",
    "plot = sns.heatmap(abs(output), vmin=.2, cbar=False, annot=True, \n",
    "                    linecolor='white', linewidth=0.5, cmap='Reds')\n",
    "subs = output.index.get_level_values(0)\n",
    "for i, sub in enumerate(subs):\n",
    "    if i and sub != subs[i - 1]:\n",
    "        ax.axhline(len(subs) - i, c=\"black\")\n",
    "conds_spacing = [x*7 for x in range(1, n_conds)]\n",
    "for i in conds_spacing:\n",
    "    ax.axvline(i, c=\"gray\")\n",
    "ax.tick_params(labelbottom='on',labeltop='on')\n",
    "ax.set(xlabel='correlation: condition and motion regressor/outliers (threshold=0.2)', \n",
    "        ylabel='subject - run #')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Are there any other QA measures you're interested in seeing? ###\n",
    "\n",
    "Remember to clear any outputs from the notebook before saving anything."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
